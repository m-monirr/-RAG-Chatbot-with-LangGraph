# Copy this file to .env and configure your settings

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434

# Model Configuration
LLM_MODEL=llama3.2
EMBEDDING_MODEL=nomic-embed-text
LLM_TEMPERATURE=0.7

# Document Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Optional: If you want to use Groq API instead of Ollama
# GROQ_API_KEY=your_api_key_here
