# ğŸ¤– RAG Chatbot with LangGraph & Ollama

<div align="center">

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![LangChain](https://img.shields.io/badge/LangChain-Latest-green.svg)
![LangGraph](https://img.shields.io/badge/LangGraph-Latest-orange.svg)
![Ollama](https://img.shields.io/badge/Ollama-llama3.2-red.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

A powerful **Retrieval-Augmented Generation (RAG)** chatbot built with **LangGraph** and **Ollama**. 

Ask questions about Large Language Models and get accurate, context-aware answers powered by Wikipedia knowledge base.

[Features](#-features) â€¢ [Installation](#-installation) â€¢ [Usage](#-usage) â€¢ [Architecture](#-architecture) â€¢ [Demo](#-demo)

</div>

---

## âœ¨ Features

- ğŸ§  **Intelligent RAG System** - Combines retrieval and generation for accurate answers
- ğŸ”„ **LangGraph Workflow** - Modular, maintainable agent architecture
- ğŸ  **Local LLM** - Runs completely offline using Ollama (llama3.2)
- ğŸ“š **Vector Database** - FAISS-powered semantic search
- âš¡ **Fast Embeddings** - Nomic embed-text for quick document retrieval
- ğŸ’¬ **Interactive CLI** - User-friendly command-line interface
- ğŸ”§ **Fully Configurable** - Easy customization via environment variables
- ğŸ“¦ **Modular Design** - Clean separation of concerns

## ğŸ—ï¸ Architecture

```mermaid
graph LR
    A[User Question] --> B[Retrieve Documents]
    B --> C[Vector Store FAISS]
    C --> D[Top-K Documents]
    D --> E[Generate Response]
    E --> F[LLM llama3.2]
    F --> G[Final Answer]
```

### Project Structure

```
langgrap/
â”œâ”€â”€ .env                      # Environment variables (API keys, configs)
â”œâ”€â”€ .gitignore               # Git ignore file
â”œâ”€â”€ README.md                # Project documentation
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ main.py                  # Main application entry point
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py         # Configuration settings
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ rag_agent.py        # RAG agent implementation
â”‚   â””â”€â”€ graph.py            # LangGraph workflow definition
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ document_loader.py  # Document loading utilities
â”‚   â”œâ”€â”€ embeddings.py       # Embedding functions
â”‚   â””â”€â”€ vector_store.py     # Vector database operations
â””â”€â”€ data/
    â””â”€â”€ faiss_index/        # FAISS vector store (generated)
```

## ğŸš€ Installation

### Prerequisites

- Python 3.10 or higher
- [Ollama](https://ollama.ai/) installed and running
- Git

### Steps

1. **Clone the repository**
   ```bash
   git clone https://github.com/m-monirr/-RAG-Chatbot-with-LangGraph.git
   cd -RAG-Chatbot-with-LangGraph
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up Ollama**
   ```bash
   # Pull the required models
   ollama pull llama3.2
   ollama pull nomic-embed-text
   ```

5. **Configure environment variables**
   ```bash
   # Create .env file
   cp .env.example .env
   # Edit .env with your configurations
   ```

## ğŸ’» Usage

### Running the Chatbot

```bash
python main.py
```

### Example Interaction

```
ğŸ¤– RAG Chatbot: Ask me anything about Large Language Models!
Type 'quit' or 'exit' to end the conversation.

You: What is a transformer model?
ğŸ¤–: A transformer model is a type of neural network architecture...

You: How does attention mechanism work?
ğŸ¤–: The attention mechanism allows the model to focus on...
```

## ğŸ“ Configuration

Edit `.env` file to customize:

```env
# LLM Settings
OLLAMA_MODEL=llama3.2
EMBEDDING_MODEL=nomic-embed-text

# Vector Store Settings
VECTOR_STORE_PATH=./data/faiss_index
TOP_K_RESULTS=4

# Document Settings
CHUNK_SIZE=500
CHUNK_OVERLAP=50
```

## ğŸ› ï¸ Technologies Used

- **LangChain** - Framework for LLM applications
- **LangGraph** - Agent workflow orchestration
- **Ollama** - Local LLM runtime
- **FAISS** - Vector similarity search
- **Python** - Programming language


<div align="center">
Made with â¤ï¸ by m-monirr
</div>
